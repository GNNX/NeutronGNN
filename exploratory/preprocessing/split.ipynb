{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/evn/ python\n",
    "\n",
    "import h5py\n",
    "import os \n",
    "import argparse\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Separate Train and Validation from Test data\")\n",
    "    parser.add_argument(\"h5_file\",\n",
    "                        type=str,\n",
    "                        help=\"Path to h5_file,\\\n",
    "                        must contain 'event_data'\")\n",
    "    parser.add_argument('output_folder', type=str,\n",
    "                        help=\"Path to output folder.\")\n",
    "    parser.add_argument('indices_folder', type=str, help=\"Path to indices folder\")\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "def load_indices(indices_file):\n",
    "    with open(indices_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    # indicies = [int(l.strip()) for l in lines if not l.isspace()]\n",
    "    indices = [int(l.strip()) for l in lines]\n",
    "    return indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EasyDict(dict):\n",
    "    def __init__(self, *args, **kwargs): super().__init__(*args, **kwargs)\n",
    "    def __getattr__(self, name): return self[name]\n",
    "    def __setattr__(self, name, value): self[name] = value\n",
    "    def __delattr__(self, name): del self[name]\n",
    "        \n",
    "config = EasyDict()\n",
    "config.h5_file = \"/app/test_data/IWCDmPMT_4pi_fulltank_test_graphnet.h5\"\n",
    "config.indices_folder = \"/app/test_data/IWCDmPMT_4pi_fulltank_test_splits/\"\n",
    "config.output_folder = \"/app/test_data/split_h5_3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = load_indices(os.path.join(config.indices_folder, \"test.txt\"))\n",
    "train_indices = load_indices(os.path.join(config.indices_folder, \"train.txt\"))\n",
    "val_indices = load_indices(os.path.join(config.indices_folder, \"val.txt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWCDmPMT_4pi_fulltank_test_graphnet_test.h5 IWCDmPMT_4pi_fulltank_test_graphnet_trainval.h5\n"
     ]
    }
   ],
   "source": [
    "basename, extension = os.path.splitext(os.path.basename(config.h5_file))\n",
    "test_filename = basename + \"_test\" + extension\n",
    "train_filename = basename + \"_trainval\" + extension\n",
    "\n",
    "print(test_filename, train_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app/test_data/split_h5_3/IWCDmPMT_4pi_fulltank_test_graphnet_test.h5 /app/test_data/split_h5_3/IWCDmPMT_4pi_fulltank_test_graphnet_trainval.h5\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(config.output_folder, exist_ok=True)\n",
    "\n",
    "test_filepath = os.path.join(config.output_folder, test_filename)\n",
    "train_filepath = os.path.join(config.output_folder, train_filename)\n",
    "\n",
    "print(test_filepath, train_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One by One copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing testing data to /app/test_data/split_h5_3/IWCDmPMT_4pi_fulltank_test_graphnet_test.h5\n",
      "Writing training and validating data to /app/test_data/split_h5_3/IWCDmPMT_4pi_fulltank_test_graphnet_trainval.h5\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(config.h5_file, 'r') as infile:\n",
    "    keys = list(infile.keys())\n",
    "    \n",
    "    print(\"Writing testing data to {}\".format(test_filepath))\n",
    "    with h5py.File(test_filepath, 'w') as outfile:\n",
    "        length = len(test_indices)\n",
    "        for key in keys:\n",
    "            original_shape = infile[key].shape\n",
    "            original_dtype = infile[key].dtype\n",
    "            new_shape = (length, ) + original_shape[1:]\n",
    "\n",
    "            dataset = outfile.create_dataset(key, shape=new_shape, dtype=original_dtype)\n",
    "\n",
    "            for i,j in enumerate(test_indices):\n",
    "                dataset[i] = infile[key][j]\n",
    "\n",
    "    # Write the trainval file\n",
    "    print(\"Writing training and validating data to {}\".format(train_filepath))\n",
    "    with h5py.File(train_filepath, 'w') as outfile:\n",
    "        length = len(train_indices) + len(val_indices)\n",
    "        for key in keys:\n",
    "            original_shape = infile[key].shape\n",
    "            original_dtype = infile[key].dtype\n",
    "            new_shape = (length, ) + original_shape[1:]\n",
    "\n",
    "            dataset = outfile.create_dataset(key, shape=new_shape, dtype=original_dtype)\n",
    "\n",
    "            for i,j in enumerate(train_indices):\n",
    "                dataset[i] = infile[key][j]\n",
    "\n",
    "            for i, j in enumerate(val_indices):\n",
    "                dataset[i+len(train_indices)] = infile[key][j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorted copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with h5py.File(config.h5_file, 'r') as infile:\n",
    "#     keys = list(infile.keys())\n",
    "\n",
    "#     with h5py.File(test_filepath, 'w') as outfile:\n",
    "#         length = len(test_indices)\n",
    "#         for key in keys:\n",
    "#             original_shape = infile[key].shape\n",
    "#             original_dtype = infile[key].dtype\n",
    "#             new_shape = (length, ) + original_shape[1:]\n",
    "            \n",
    "#             sorted_indices = sorted(test_indices)\n",
    "#             dataset = outfile.create_dataset(key, shape=new_shape, dtype=original_dtype,\n",
    "#                                             data=infile[key][sorted_indices])\n",
    "            \n",
    "    \n",
    "#     with h5py.File(train_filepath, 'w') as outfile:\n",
    "#         length = len(train_indices) + len(val_indices)\n",
    "#         for key in keys:\n",
    "#             original_shape = infile[key].shape\n",
    "#             original_dtype = infile[key].dtype\n",
    "#             new_shape = (length, ) + original_shape[1:]\n",
    "            \n",
    "#             dataset = outfile.create_dataset(key, shape=new_shape, dtype=original_dtype)\n",
    "            \n",
    "#             sorted_indices = sorted(train_indices)\n",
    "#             dataset[:len(train_indices)] = infile[key][sorted_indices]\n",
    "#             sorted_indices = sorted(val_indices)\n",
    "#             dataset[len(train_indices):] = infile[key][sorted_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorted batch copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with h5py.File(config.h5_file, 'r') as infile:\n",
    "#     keys = list(infile.keys())\n",
    "\n",
    "#     with h5py.File(test_filepath, 'w') as outfile:\n",
    "#         length = len(test_indices)\n",
    "#         for key in keys:\n",
    "#             original_shape = infile[key].shape\n",
    "#             original_dtype = infile[key].dtype\n",
    "#             new_shape = (length, ) + original_shape[1:]\n",
    "            \n",
    "#             dataset = outfile.create_dataset(key, shape=new_shape, dtype=original_dtype)\n",
    "            \n",
    "#             sorted_indices = sorted(test_indices)\n",
    "#             i = 0\n",
    "#             while i < len(sorted_indices):\n",
    "#                 end = max(len(sorted_indices), i+128)\n",
    "#                 dataset[i:end] = infile[key][sorted_indices[i:end]]\n",
    "#                 i = end\n",
    "    \n",
    "#     with h5py.File(train_filepath, 'w') as outfile:\n",
    "#         length = len(train_indices) + len(val_indices)\n",
    "#         for key in keys:\n",
    "#             original_shape = infile[key].shape\n",
    "#             original_dtype = infile[key].dtype\n",
    "#             new_shape = (length, ) + original_shape[1:]\n",
    "            \n",
    "#             dataset = outfile.create_dataset(key, shape=new_shape, dtype=original_dtype)\n",
    "            \n",
    "#             sorted_indices = sorted(train_indices)\n",
    "#             i = 0\n",
    "#             while i < len(sorted_indices):\n",
    "#                 end = max(len(sorted_indices), i+128)\n",
    "#                 dataset[i:end] = infile[key][sorted_indices[i:end]]\n",
    "#                 i = end\n",
    "            \n",
    "            \n",
    "#             sorted_indices = sorted(val_indices)\n",
    "#             i = 0\n",
    "#             while i < len(sorted_indices):\n",
    "#                 end = max(len(sorted_indices), i+128)\n",
    "#                 dataset[i+len(train_indices):end+len(train_indices)] = infile[key][sorted_indices[i:end]]\n",
    "#                 i = end           \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits_dir = os.path.join(config.output_folder, basename + \"_splits\")\n",
    "# os.makedirs(splits_dir, exist_ok=True)\n",
    "\n",
    "# with open(os.path.join(splits_dir, 'train.txt'), 'w') as f:\n",
    "#     f.writelines([\"{}\\n\".format(i) for i in range(len(train_indices))])\n",
    "    \n",
    "# with open(os.path.join(splits_dir, 'val.txt'), 'w') as f:\n",
    "#     f.writelines([\"{}\\n\".format(i) for i in range(len(train_indices), len(train_indices) + len(val_indices))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
