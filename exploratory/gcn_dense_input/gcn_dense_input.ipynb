{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, ChebConv  # noqa\n",
    "from torch_geometric.nn import global_max_pool\n",
    "from torch_geometric.data import Batch, Data\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.int64 torch.int64\n"
     ]
    }
   ],
   "source": [
    "# dataset = 'Cora'\n",
    "# __file__ = \"/app/pytorch_geometric/examples/gcn.py\"\n",
    "\n",
    "# path = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', dataset)\n",
    "# dataset = Planetoid(path, dataset, T.NormalizeFeatures())\n",
    "# data = dataset[0]\n",
    "\n",
    "# print(data.x.dtype, data.y.dtype, data.edge_index.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(indices=tensor([[    0,     0,     1,  ..., 17998, 17999, 17999],\n",
      "                       [    0,     1,     0,  ...,     1,     0,     1]]),\n",
      "       values=tensor([-1.0178, -0.7190, -1.2644,  ...,  0.6298, -0.8303,\n",
      "                       1.1015]),\n",
      "       size=(18000, 2), nnz=36000, layout=torch.sparse_coo)\n",
      "tensor(indices=tensor([[    0,     0,     0,  ..., 15807, 15807, 15807],\n",
      "                       [    1,    11,    18,  ..., 15804, 15805, 15806]]),\n",
      "       values=tensor([1, 1, 1,  ..., 1, 1, 1]),\n",
      "       size=(18000, 18000), nnz=66552, layout=torch.sparse_coo)\n"
     ]
    }
   ],
   "source": [
    "nodes = 18000\n",
    "hits = 18000\n",
    "features = 2\n",
    "edges_per_node = 4\n",
    "\n",
    "x = torch.zeros([nodes, features], dtype=torch.float32)\n",
    "# x_mask = torch.zeros([nodes,], dtype=torch.uint8)\n",
    "y = torch.zeros([1], dtype=torch.int64)\n",
    "edge_index = torch.zeros([nodes, nodes], dtype=torch.int64)\n",
    "\n",
    "perm = np.random.permutation(nodes)[:hits]\n",
    "# x_mask[perm] = 1\n",
    "x[perm] = torch.randn(hits, features, dtype=torch.float32)\n",
    "\n",
    "for _ in range(edges_per_node):\n",
    "    edge_index[np.random.permutation(nodes), np.random.permutation(nodes)] = 1\n",
    "# for _ in range(edges_per_node):\n",
    "#     edge_index[np.random.permutation(nodes)[:hits], np.random.permutation(nodes)[:hits]] = 1\n",
    "\n",
    "# import pickle\n",
    "# with open(\"edges_dict.pkl\", 'rb') as f:\n",
    "#     edges = pickle.load(f)\n",
    "    \n",
    "#     for k,vs in edges.items():\n",
    "#         for v in vs:\n",
    "#             edge_index[k,v] = 1\n",
    "\n",
    "data = Data(x=x, y=y, edge_index=edge_index.to_sparse()._indices())\n",
    "\n",
    "print(x.to_sparse())\n",
    "print(edge_index.to_sparse())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2129664])\n",
      "tensor(indices=tensor([[     0,      0,      1,  ..., 575998, 575999, 575999],\n",
      "                       [     0,      1,      0,  ...,      1,      0,      1]]),\n",
      "       values=tensor([-1.0178, -0.7190, -1.2644,  ...,  0.6298, -0.8303,\n",
      "                       1.1015]),\n",
      "       size=(576000, 2), nnz=1152000, layout=torch.sparse_coo)\n"
     ]
    }
   ],
   "source": [
    "batch = Batch.from_data_list([data for i in range(32)])\n",
    "\n",
    "print(batch.edge_index.shape)\n",
    "print(batch.x.to_sparse())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(2, 16, cached=True)\n",
    "        self.conv2 = GCNConv(16, 16, cached=True)\n",
    "        self.conv3 = GCNConv(16, 5, cached=True)\n",
    "\n",
    "#         self.conv1 = ChebConv(2, 16, K=2)\n",
    "#         self.conv2 = ChebConv(16, 5, K=2)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = global_max_pool(x, batch)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model= Net().to(device)\n",
    "batch = batch.to(device)\n",
    "# data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "#     output = model(batch.x.to_sparse(), batch.edge_index, batch.batch)\n",
    "    output = model(batch.x, batch.edge_index, batch.batch)\n",
    "\n",
    "    F.nll_loss(output, batch.y).backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    logits = model(batch.x, batch.edge_index, batch.batch)\n",
    "    pred = logits.argmax(1)\n",
    "    acc = pred.eq(batch.y).sum().item() / batch.y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.126508951187134\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "best_acc = 0\n",
    "batch.x = batch.x.to_sparse()\n",
    "for epoch in range(1, 201):\n",
    "    train()\n",
    "#     train_acc = test()\n",
    "#     if train_acc > best_acc:\n",
    "#         best_acc = train_acc\n",
    "#     log = 'Epoch: {:03d}, Train: {:.4f}, Best: {:.4f}'\n",
    "#     print(log.format(epoch, train_acc, best_acc))\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
